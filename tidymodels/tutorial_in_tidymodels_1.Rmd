---
title: "Tutorial on Tidymodel part I"
output: md_document
---

Reproduzindo este [artigo](https://hansjoerg.me/2020/02/09/tidymodels-for-machine-learning/) sobre `tidymodels` do [Hansjörg Plieninger](https://hansjoerg.me/page/about/)

# Tutorial on tidymodels for Machine Learning

## Setup

```{r loadlibs, message=FALSE, warning=FALSE}
library(conflicted)
library(tidymodels)
library(tidyverse)
library(ggrepel)
library(corrplot)
library(skimr)

conflict_prefer("filter","dplyr")

ggplot2::theme_set(theme_light())
```

## Dataset: `Diamonds`

```{r diamond_plot}

data("diamonds")

head(diamonds,10)

diamonds %>% 
  sample_n(2000) %>% 
  mutate_if(is.factor, as.numeric) %>% 
  select(price, everything()) %>% 
  cor() %>% 
  {.[order(abs(.[,1]), decreasing = T),
     order(abs(.[,1]), decreasing = T)]} %>% 
  corrplot(method = "number", type="upper", mar=c(0,0,1.5,0), 
           title="Correlations between price and various features of diamonds")
  

```

```{r}

diamonds %>% 
  skim()

```


## Separating Testing and Training Data: `rsample`

```{r}
# you know: the life, the universer... 
set.seed(42)

# training/test
dia_split <- initial_split(diamonds, prop = .1, strata = price)
dia_train <- training(dia_split)
dia_test  <- testing(dia_split)

dim(dia_train)
dim(dia_test)

# cv-folds
dia_vfold <- vfold_cv(dia_train, v=3, repeats=1, strata=price)


dia_vfold %>% 
  mutate(df_ana=map(splits, analysis),
         df_ass=map(splits, assessment)) -> folds


```

## Data Pre-Processing and Feature Engineering: `recipes`

The plot below indicates that there may be a nonlinear relationship between price and carat, and I want to address that using higher-order terms.

```{r}
qplot(carat, price, data = dia_train) +
    scale_y_continuous(trans = log_trans(), labels = function(x) round(x, -2)) +
    geom_smooth(method = "lm", formula = "y ~ poly(x, 4)") +
    labs(title = "Nonlinear relationship between price and carat of diamonds",
         subtitle = "The degree of the polynomial is a potential tuning parameter")
```

```{r}
dia_rec <- recipe(price~., data=dia_train) %>% 
  # log no preço
  step_log(all_outcomes()) %>% 
  # normializa valores (que fatoriais)
  step_normalize(all_predictors(), -all_nominal()) %>% 
  # OHE dos fatoriais
  step_dummy(all_nominal()) %>% 
  # cria uma feature (?) de polinomial
  step_poly(carat, degree = 4)

prep(dia_rec)

```

```{r}

# apply the recipe in the train data
dia_prep <- prep(dia_rec)

# extract transformed training data
dia_juiced <- juice(dia_prep)

# apply the recipe in a new data
bake(dia_prep, dia_test)

```

## Defining and Fitting Models: `parsnip`

The parsnip package has wrappers around many1 popular machine learning algorithms, and you can fit them using a unified interface. This is extremely helpful, since you have to remember only one rather then dozens of interfaces.

```{r}

# regression example
lm_model <- linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("lm")

rf_model <- rand_forest(mtry=3, trees=500, min_n=5) %>% 
  set_mode("regression") %>% 
  set_engine("ranger", importance="impurity")

```

```{r}

lm_fit <- fit(lm_model, price~., dia_juiced)
lm_fit

# rf_fit <- fit(rf_model, price~., dia_juiced)
# rf_fit
```

## Summarizing Fitted Models: broom


```{r}

glance(lm_fit$fit)
tidy(lm_fit$fit)
# rf_fit$fit

lm_train_predicted <- augment(lm_fit$fit) %>% 
  rowid_to_column() %>% 
  select(rowid, price, .fitted:.std.resid)
```

```{r}

ggplot(lm_train_predicted, aes(.fitted, price)) +
  geom_point(alpha=.2)+
  ggrepel::geom_label_repel(aes(label=rowid), data=filter(lm_train_predicted, abs(.resid)>2)) +
  labs(title="Actual vs. Predicted Price of Diamonds")

```

## Evaluating Model Performance: `yardstick`

We already saw performance measures RMSE and R squared in the output of glance() above. The yardstick package is specifically designed for such measures for both numeric and categorical outcomes, and it plays well with grouped predictions (e.g., from cross-validation).

Let’s use rsample, parsnip, and yardstick for cross-validation to get a more accurate estimation of RMSE.

```{r}

# 3 CV fold, we can extract the "train" data and the "test/validation" data of each fold
lm_fit2 <- dia_vfold %>% 
  mutate(df_ana = map(splits, analysis),
         df_ass = map(splits, assessment)) 


lm_fit2_result <- lm_fit2 %>% 
  mutate(
    recipe = map(df_ana, ~prep(dia_rec, training = .x)), #prepara a receita para um dos CVs
    df_ana = map(recipe, juice), # extrai os dados transformados na receita
    df_ass = map2(recipe, df_ass, ~bake(.x, new_data=.y)) #aplica a receita aos dados de assessment
  ) %>% 
  mutate(
    # fita um lm_model ao conjunto de dados de analise transformado
    model_fit = map(df_ana, ~fit(lm_model, price~., data=.x)) 
  ) %>% 
  mutate(
    # aplica o modelo ao dado de assessment
    model_pred = map2(model_fit, df_ass, ~predict(.x, new_data=.y))
  )

select(lm_fit2_result, id, recipe:model_pred)

```

Now, we can extract the actual prices price from the assessment data and compare them to the predicted prices .pred. Then, the yardstick package comes into play: The function metrics() calculates three different metrics for numeric outcomes. Furthermore, it automatically recognizes that lm_preds is grouped by folds and thus calculates the metrics for each fold.

```{r}
lm_preds <- lm_fit2_result %>% 
  mutate( res=map2(df_ass, model_pred, ~data.frame(price=.x$price, .pred=.y$.pred))) %>% 
  select(id, res) %>% 
  unnest(res) %>% 
  group_by(id)

yardstick::metrics(lm_preds, truth=price, estimate=.pred)
```

